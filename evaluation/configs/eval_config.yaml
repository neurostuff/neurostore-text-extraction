# Evaluation Configuration
version: "1.0.0"

metrics:
  accuracy: true
  precision: true 
  recall: true
  per_field_metrics:
    - group_count
    - male_count
    - female_count
    - age_mean
    - age_minimum
    - age_maximum

ground_truth:
  source: "labelrepo"
  # Version of ground truth data to use
  version: "latest"
  
test_sets:
  # Default test set configuration
  default:
    num_studies: 20
    extractors:
      - participant_demographics
      - nv_extract

baseline:
  # Minimum required metrics to pass evaluation
  thresholds:
    accuracy: 0.8
    precision: 0.75
    recall: 0.75
