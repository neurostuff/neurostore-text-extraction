<?xml version='1.0' encoding='UTF-8'?>
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article">
  <?properties open_access?>
  <front>
    <journal-meta>
      <journal-id journal-id-type="nlm-ta">Front Psychol</journal-id>
      <journal-id journal-id-type="iso-abbrev">Front Psychol</journal-id>
      <journal-id journal-id-type="publisher-id">Front. Psychol.</journal-id>
      <journal-title-group>
        <journal-title>Frontiers in Psychology</journal-title>
      </journal-title-group>
      <issn pub-type="epub">1664-1078</issn>
      <publisher>
        <publisher-name>Frontiers Media S.A.</publisher-name>
      </publisher>
    </journal-meta>
    <article-meta>
      <article-id pub-id-type="pmid">26321993</article-id>
      <article-id pub-id-type="pmc">4530666</article-id>
      <article-id pub-id-type="doi">10.3389/fpsyg.2015.01181</article-id>
      <article-categories>
        <subj-group subj-group-type="heading">
          <subject>Psychology</subject>
          <subj-group>
            <subject>Original Research</subject>
          </subj-group>
        </subj-group>
      </article-categories>
      <title-group>
        <article-title>Self perception and facial emotion perception of others in anorexia nervosa</article-title>
      </title-group>
      <contrib-group>
        <contrib contrib-type="author">
          <name>
            <surname>Phillipou</surname>
            <given-names>Andrea</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <xref ref-type="author-notes" rid="fn001">
            <sup>*</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/112379"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Abel</surname>
            <given-names>Larry A.</given-names>
          </name>
          <xref ref-type="aff" rid="aff1">
            <sup>1</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/72336"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Castle</surname>
            <given-names>David J.</given-names>
          </name>
          <xref ref-type="aff" rid="aff2">
            <sup>2</sup>
          </xref>
          <xref ref-type="aff" rid="aff3">
            <sup>3</sup>
          </xref>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Hughes</surname>
            <given-names>Matthew E.</given-names>
          </name>
          <xref ref-type="aff" rid="aff6">
            <sup>6</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Gurvich</surname>
            <given-names>Caroline</given-names>
          </name>
          <xref ref-type="aff" rid="aff7">
            <sup>7</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/112237"/>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Nibbs</surname>
            <given-names>Richard G.</given-names>
          </name>
          <xref ref-type="aff" rid="aff6">
            <sup>6</sup>
          </xref>
        </contrib>
        <contrib contrib-type="author">
          <name>
            <surname>Rossell</surname>
            <given-names>Susan L.</given-names>
          </name>
          <xref ref-type="aff" rid="aff4">
            <sup>4</sup>
          </xref>
          <xref ref-type="aff" rid="aff6">
            <sup>6</sup>
          </xref>
          <xref ref-type="aff" rid="aff7">
            <sup>7</sup>
          </xref>
          <uri xlink:type="simple" xlink:href="http://loop.frontiersin.org/people/68726"/>
        </contrib>
      </contrib-group>
      <aff id="aff1">
        <sup>1</sup>
        <institution>Department of Optometry and Vision Sciences, The University of Melbourne</institution>
        <country>Melbourne, VIC, Australia</country>
      </aff>
      <aff id="aff2">
        <sup>2</sup>
        <institution>Department of Psychiatry, The University of Melbourne</institution>
        <country>Melbourne, VIC, Australia</country>
      </aff>
      <aff id="aff3">
        <sup>3</sup>
        <institution>Department of Mental Health, St Vincent’s Hospital, Melbourne</institution>
        <country>VIC, Australia</country>
      </aff>
      <aff id="aff4">
        <sup>4</sup>
        <institution>Department of Psychiatry, St Vincent’s Hospital, Melbourne</institution>
        <country>VIC, Australia</country>
      </aff>
      <aff id="aff5">
        <sup>5</sup>
        <institution>Faculty of Health Sciences, Australian Catholic University, Melbourne</institution>
        <country>VIC, Australia</country>
      </aff>
      <aff id="aff6">
        <sup>6</sup>
        <institution>Brain and Psychological Sciences Research Centre, Swinburne University of Technology, Melbourne</institution>
        <country>VIC, Australia</country>
      </aff>
      <aff id="aff7">
        <sup>7</sup>
        <institution>Monash Alfred Psychiatry Research Centre, Melbourne</institution>
        <country>VIC, Australia</country>
      </aff>
      <author-notes>
        <fn fn-type="edited-by">
          <p>Edited by: <italic>Marco Steinhauser, Catholic University of Eichstätt-Ingolstadt, Germany</italic></p>
        </fn>
        <fn fn-type="edited-by">
          <p>Reviewed by: <italic>Tobias Flaisch, University of Konstanz, Germany; Martin Ernst Maier, Catholic University Eichstätt-Ingolstadt, Germany</italic></p>
        </fn>
        <corresp id="fn001">*Correspondence: <italic>Andrea Phillipou, Department of Mental Health, St Vincent’s Hospital, Fitzroy, Melbourne, VIC 3065, Australia, <email xlink:type="simple">ap@unimelb.edu.au</email></italic></corresp>
        <fn fn-type="other" id="fn002">
          <p>This article was submitted to Cognition, a section of the journal Frontiers in Psychology</p>
        </fn>
      </author-notes>
      <pub-date pub-type="epub">
        <day>10</day>
        <month>8</month>
        <year>2015</year>
      </pub-date>
      <pub-date pub-type="collection">
        <year>2015</year>
      </pub-date>
      <volume>6</volume>
      <elocation-id>1181</elocation-id>
      <history>
        <date date-type="received">
          <day>02</day>
          <month>6</month>
          <year>2015</year>
        </date>
        <date date-type="accepted">
          <day>27</day>
          <month>7</month>
          <year>2015</year>
        </date>
      </history>
      <permissions>
        <copyright-statement>Copyright © 2015 Phillipou, Abel, Castle, Hughes, Gurvich, Nibbs and Rossell.</copyright-statement>
        <copyright-year>2015</copyright-year>
        <copyright-holder>Phillipou, Abel, Castle, Hughes, Gurvich, Nibbs and Rossell</copyright-holder>
        <license xlink:href="http://creativecommons.org/licenses/by/4.0/">
          <license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License (CC BY). The use, distribution or reproduction in other forums is permitted, provided the original author(s) or licensor are credited and that the original publication in this journal is cited, in accordance with accepted academic practice. No use, distribution or reproduction is permitted which does not comply with these terms.</license-p>
        </license>
      </permissions>
      <abstract>
        <p><bold>Background:</bold> Whether individuals with anorexia nervosa (AN) are able to accurately perceive emotions from faces of others is unclear. Furthermore, whether individuals with AN process images of their own face differently to healthy individuals has thus far not been investigated. Therefore, the aim of this study was to investigate facial affect processing and the processing of one’s own face through measures of emotion identification, functional magnetic resonance imaging (fMRI) and eyetracking.</p>
        <p><bold>Methods:</bold> Twenty-four females with AN and 25 matched healthy control participants were presented with an implicit emotion processing task during fMRI and eyetracking, followed by an explicit emotion identification task.</p>
        <p><bold>Results:</bold> The AN group were found to ‘hyperscan’ stimuli and avoided visually attending to salient features of their own face images. Results of the fMRI revealed increased activity to own face stimuli in AN in the right inferior and middle temporal gyri, and right lingual gyrus. AN participants were not found to display emotion identification deficits to the standard emotional face stimuli.</p>
        <p><bold>Discussion:</bold> The findings are discussed in terms of increased anxiety to disorder-relevant stimuli in AN. Potential clinical implications are discussed in relation to the use of eyetracking techniques to improve the perception of self in AN.</p>
      </abstract>
      <kwd-group>
        <kwd>eating disorders</kwd>
        <kwd>fMRI</kwd>
        <kwd>eyetracking</kwd>
        <kwd>eye movements</kwd>
        <kwd>affect</kwd>
      </kwd-group>
      <counts>
        <fig-count count="1"/>
        <table-count count="2"/>
        <equation-count count="0"/>
        <ref-count count="48"/>
        <page-count count="9"/>
        <word-count count="0"/>
      </counts>
    </article-meta>
  </front>
  <body>
    <sec>
      <title>Introduction</title>
      <p>Anorexia nervosa (AN) is a psychiatric condition characterized by a significantly low body weight, a fear of weight gain and a disturbance in the experience of one’s own body weight or shape (<xref rid="B1" ref-type="bibr">American Psychiatric Association, 2013</xref>). A common pathognomonic psychological factor in AN is the disturbance of body image (<xref rid="B41" ref-type="bibr">Tovée et al., 2000</xref>). AN also significantly overlaps with anxiety disorders in terms of symptoms and phenomenology, particularly obsessive compulsive disorder (<xref rid="B40" ref-type="bibr">Thiel et al., 1995</xref>; <xref rid="B20" ref-type="bibr">Kaye et al., 2004</xref>). Additionally, AN has long been associated with deficits in the perception of emotion; in her pioneering work, <xref rid="B5" ref-type="bibr">Bruch (1962)</xref> observed a marked deficiency in the description of feelings and emotional responses in patients with AN. Later research has linked these deficiencies to the construct of alexithymia, which is defined as a difficulty in identifying and describing subjective feelings, a difficulty in distinguishing between feelings and the bodily sensations of emotional arousal, an externally oriented cognitive style, and a lack of imaginal capacity and fantasy (<xref rid="B30" ref-type="bibr">Nemiah et al., 1976</xref>). Increased rates of alexithymia have been consistently reported in AN (<xref rid="B3" ref-type="bibr">Bourke et al., 1992</xref>; <xref rid="B22" ref-type="bibr">Kessler et al., 2006</xref>; <xref rid="B42" ref-type="bibr">Troop et al., 2006</xref>), though whether individuals with AN have difficulty in the processing of other people’s emotions has not been significantly elucidated.</p>
      <p>A number of studies have reported that AN patients perform poorly on tasks probing human face emotion identification (also referred to as ‘facial affect processing’). Some authors have reported that this deficit was not specific to any particular emotion (<xref rid="B19" ref-type="bibr">Jänsch et al., 2009</xref>), while others have found deficits that are specific to the identification of surprise (<xref rid="B22" ref-type="bibr">Kessler et al., 2006</xref>; <xref rid="B25" ref-type="bibr">Legenbauer et al., 2008</xref>), sadness (<xref rid="B24" ref-type="bibr">Kucharska-Pietura et al., 2004</xref>; <xref rid="B33" ref-type="bibr">Pollatos et al., 2008</xref>), disgust (<xref rid="B33" ref-type="bibr">Pollatos et al., 2008</xref>), and fear (<xref rid="B24" ref-type="bibr">Kucharska-Pietura et al., 2004</xref>). In only one study of which we are aware, the authors did not find any emotion identification deficit in AN (<xref rid="B28" ref-type="bibr">Mendlewicz et al., 2005</xref>). The consistency of these findings has prompted researchers to explore the neurobiological basis of this impairment in AN using neuroimaging techniques.</p>
      <p>To date, only two published functional magnetic resonance imaging (fMRI) studies have investigated facial affect processing in AN. <xref rid="B12" ref-type="bibr">Fonville et al. (2014)</xref> found that AN patients exhibited increased blood-oxygen level dependent (BOLD) activation in the right fusiform gyrus in response to mildly happy, prototypically happy, and neutral human face expressions compared to controls. In contrast, <xref rid="B6" ref-type="bibr">Cowdrey et al. (2012)</xref> did not find any group differences with their paradigm that used fearful and happy human face expressions. However, the findings of these studies have limited utility as neither contrasted the affect images with neutral affect images to control for differential between group face processing <italic>per se</italic>; <xref rid="B12" ref-type="bibr">Fonville et al. (2014)</xref> contrasted the emotions to a baseline (fixation cross) and <xref rid="B6" ref-type="bibr">Cowdrey et al. (2012)</xref> contrasted fearful and happy conditions with one another.</p>
      <p>Another related set of studies have analyzed visual scanpaths and have revealed critical information for understanding face emotion processing in a range of psychiatric conditions. During face stimulus processing, healthy individuals focus on salient features such as the eyes, nose, and mouth (<xref rid="B45" ref-type="bibr">Walker-Smith et al., 1977</xref>), whereas patients with psychiatric conditions such as schizophrenia and autism spectrum disorder, show reduced visual attention to these features (<xref rid="B26" ref-type="bibr">Loughland et al., 2002</xref>; <xref rid="B9" ref-type="bibr">De Wit et al., 2008</xref>). Furthermore, although poorer attention to salient features has been found in psychiatric populations such as schizophrenia during implicit emotion processing tasks, typical attention to salient features has been found when explicit task instructions are given (<xref rid="B8" ref-type="bibr">Delerue et al., 2010</xref>). Individuals with psychiatric conditions also show different scanpath strategies: those with anxiety disorders such as social anxiety disorder ‘hyperscan’ (increased scanpath lengths with fixations of shorter duration) face stimuli (<xref rid="B18" ref-type="bibr">Horley et al., 2003</xref>), whereas those with schizophrenia show a restricted scanpath of fewer fixations of longer duration, and reduced scanpath lengths (<xref rid="B26" ref-type="bibr">Loughland et al., 2002</xref>). Whether individuals with AN also exhibit discrepant visual scanpath behavior when viewing face stimuli relative to healthy individuals, has thus far not been thoroughly investigated. During a free-viewing task where participants were presented with whole body stimuli and face stimuli, <xref rid="B46" ref-type="bibr">Watson et al. (2010)</xref> reported reduced attention to the eye region of face stimuli, and less time visually attending face regions when whole bodies were presented in AN. However, the findings of that study are limited as no attempt was made to standardize the stimuli acquired from a dating website. <xref rid="B13" ref-type="bibr">Freeman et al. (1991)</xref>, on the other hand, presented participants images of their own bodies photographed in a black leotard and reported that while healthy controls spent relatively the same amount of time focusing on four interest areas (face, chest, abdomen, and legs), individuals with AN spent more time looking at the their legs and abdomen and less time looking at the face, suggesting an avoidance of fixating one’s own face in AN.</p>
      <p>The aim of the current study was to investigate the processing of emotional faces of others, and faces of self, in AN. Participants performed an implicit emotion processing task that involved gender identification of stimuli while undergoing fMRI and eyetracking, and an explicit emotion identification task outside the scanner during eyetracking. Functional imaging studies of emotional face perception are typically performed as implicit tasks, such as gender decision tasks, rather than explicit tasks as they are less cognitively demanding and do not interfere with emotional processing. As explicit tasks have a higher cognitive demand, more frontal areas are involved and it is more difficult to observe the areas involved in emotion processing (<xref rid="B7" ref-type="bibr">Critchley et al., 2000</xref>; <xref rid="B16" ref-type="bibr">Gorno-Tempini et al., 2001</xref>). Performing the task both implicitly and explicitly also allowed for the investigation of emotion perception and scanpaths under different conditions. As scanning behaviors have not previously been specifically investigated in AN, individuals with AN were expected to exhibit similar scanning behaviors to related conditions such as anxiety disorders, namely, hyperscanning of face stimuli during both tasks (i.e., increased fixations of shorter duration). Similarly to other psychiatric conditions, we further hypothesized that AN participants would show an avoidance of salient features of the emotional face stimuli during the implicit task. As typical attention to salient features has been found when explicit task instructions are given in populations that demonstrate poor attention to salient features during implicit tasks (<xref rid="B8" ref-type="bibr">Delerue et al., 2010</xref>), groups were not expected to differ in areas of attentional focus during the explicit task. In relation to participants’ own face stimuli and given the avoidance of looking at one’s own face as reported by <xref rid="B13" ref-type="bibr">Freeman et al. (1991)</xref>, the AN group were hypothesized to show less attention to salient features during both tasks. Individuals with AN were also expected to show emotion identification deficits to face stimuli displaying negative emotion, but were not expected to show emotion recognition difficulties to their own face when they were asked to display a neutral expression. Related to this hypothesis, the AN group were expected to manifest reduced activity in limbic areas of the brain to negative affect stimuli, relative to neutral control faces; and to show reduced activity to stimuli of their own face in frontoparietal brain areas which are involved in the processing of ones’ own face (<xref rid="B43" ref-type="bibr">Uddin et al., 2005</xref>).</p>
    </sec>
    <sec sec-type="materials|methods" id="s1">
      <title>Materials and Methods</title>
      <p>This study was approved by the human research ethics departments at The University of Melbourne, Swinburne University of Technology, The Melbourne Clinic, The Austin Hospital, and St Vincent’s Hospital; all in Melbourne, VIC, Australia. Informed written consent was obtained from all participants. All procedures contributing to this work comply with the ethical standards of the relevant national and institutional committees on human experimentation and with the Helsinki Declaration of 1975, as revised in 2008.</p>
      <sec>
        <title>Participants</title>
        <p>Twenty-four right-handed individuals with AN and 25 healthy control (HC) individuals were recruited for the study. One participant in the AN group declined to have her own face included among the stimuli and her data were not included in the analysis. A programming error resulted in one HC participant being presented with too few own face stimuli and her data were excluded. Technical difficulties encountered with use of the eyetracking equipment in the MRI resulted in the data of three AN participants and three HC participants being excluded, allowing eyetracking analyses to be conducted on 20 AN and 21 HC participants. All 23 AN and 24 HC participants’ data were included in the fMRI and emotion identification analyses.</p>
        <p>HCs were recruited through public advertisements, whereas AN participants were recruited through public advertisements, the Body Image and Eating Disorders Treatment and Recovery Service at the Austin and St Vincent’s Hospitals, and The Melbourne Clinic (all located in Melbourne, VIC, Australia). All participants were English speaking, had no history of significant brain injury or neurological condition, no significant ocular pathology and normal (or corrected to normal) visual acuity. Controls were required to have no history of an eating disorder or other mental illness; they were also required to not be taking any medications apart from hormonal contraceptives (11 HC participants were taking this medication). AN participants were instructed to continue with their normal medications, which were: selective serotonin reuptake inhibitors (SSRIs) (10), atypical antipsychotics (10), benzodiazepines (5), serotonin-noradrenaline reuptake inhibitors (SNRIs) (3), hormonal contraceptives (3), melatonergic antidepressants (2), noradrenergic and specific serotonergic antidepressant (NaSSA) (1), and cyclopyrrolones (1). Medications that patients were taking, such as benzodiazepines and atypical antipsychotics have been found to moderately reduce saccadic peak velocity (<xref rid="B34" ref-type="bibr">Reilly et al., 2008</xref>), but do not affect scanpaths to the best of our knowledge.</p>
        <p>The Mini International Neuropsychiatric Interview, 5.0.0 (MINI; <xref rid="B37" ref-type="bibr">Sheehan et al., 1998</xref>) was used to screen participants for major Axis I psychiatric disorders according to the Diagnostic and Statistical Manual of Mental Disorders (DSM-IV). It was also used to confirm diagnoses of AN, with the exception of the amenorrhea criterion which is not included in DSM-5 criteria. AN was required to be the primary diagnosis of the AN group; participants with comorbid psychiatric conditions, other than psychotic conditions, were not excluded as this would not have represented a typical AN sample.</p>
        <p>Premorbid intelligence was estimated using the Wechsler Test of Adult Reading (WTAR; <xref rid="B47" ref-type="bibr">Wechsler, 2001</xref>). Eating disorder symptomatology was investigated with the Eating Disorders Examination Questionnaire (EDE-Q; <xref rid="B11" ref-type="bibr">Fairburn, 2008</xref>) and alexithymia with the Toronto Alexithymia Scale (TAS-20; <xref rid="B2" ref-type="bibr">Bagby et al., 1994</xref>) (<bold>Table <xref ref-type="table" rid="T1">1</xref></bold>).</p>
        <table-wrap id="T1" position="float">
          <label>Table 1</label>
          <caption>
            <p>Participant information.</p>
          </caption>
          <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
            <thead>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <th valign="top" align="center" colspan="2" rowspan="1">AN<hr/></th>
                <th valign="top" align="center" colspan="3" rowspan="1">HC<hr/></th>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <th valign="top" align="left" rowspan="1" colspan="1">
                  <italic>M</italic>
                </th>
                <th valign="top" align="left" rowspan="1" colspan="1">SD</th>
                <th valign="top" align="left" rowspan="1" colspan="1">
                  <italic>M</italic>
                </th>
                <th valign="top" align="left" rowspan="1" colspan="1">SD</th>
                <th valign="top" align="left" rowspan="1" colspan="1">
                  <italic>p</italic>
                </th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Age</td>
                <td valign="top" align="left" rowspan="1" colspan="1">22.18</td>
                <td valign="top" align="left" rowspan="1" colspan="1">5.45</td>
                <td valign="top" align="left" rowspan="1" colspan="1">22.64</td>
                <td valign="top" align="left" rowspan="1" colspan="1">3.25</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.725</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Premorbid IQ</td>
                <td valign="top" align="left" rowspan="1" colspan="1">104.22</td>
                <td valign="top" align="left" rowspan="1" colspan="1">8.07</td>
                <td valign="top" align="left" rowspan="1" colspan="1">105.71</td>
                <td valign="top" align="left" rowspan="1" colspan="1">7.13</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.505</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">BMI</td>
                <td valign="top" align="left" rowspan="1" colspan="1">16.47</td>
                <td valign="top" align="left" rowspan="1" colspan="1">1.13</td>
                <td valign="top" align="left" rowspan="1" colspan="1">22.36</td>
                <td valign="top" align="left" rowspan="1" colspan="1">3.66</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.001</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Illness duration</td>
                <td valign="top" align="left" rowspan="1" colspan="1">6.89</td>
                <td valign="top" align="left" rowspan="1" colspan="1">7.28</td>
                <td valign="top" align="left" rowspan="1" colspan="1">–</td>
                <td valign="top" align="left" rowspan="1" colspan="1">–</td>
                <td valign="top" align="left" rowspan="1" colspan="1">–</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">Age of illness onset</td>
                <td valign="top" align="left" rowspan="1" colspan="1">15.74</td>
                <td valign="top" align="left" rowspan="1" colspan="1">3.24</td>
                <td valign="top" align="left" rowspan="1" colspan="1">–</td>
                <td valign="top" align="left" rowspan="1" colspan="1">–</td>
                <td valign="top" align="left" rowspan="1" colspan="1">–</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">EDE-Q restraint</td>
                <td valign="top" align="left" rowspan="1" colspan="1">3.84</td>
                <td valign="top" align="left" rowspan="1" colspan="1">1.38</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.58</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.64</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.001</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">EDE-Q eating concern</td>
                <td valign="top" align="left" rowspan="1" colspan="1">3.79</td>
                <td valign="top" align="left" rowspan="1" colspan="1">1.27</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.25</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.32</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.001</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">EDE-Q shape concern</td>
                <td valign="top" align="left" rowspan="1" colspan="1">5.02</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.92</td>
                <td valign="top" align="left" rowspan="1" colspan="1">1.15</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.86</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.001</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">EDE-Q weight concern</td>
                <td valign="top" align="left" rowspan="1" colspan="1">4.50</td>
                <td valign="top" align="left" rowspan="1" colspan="1">1.45</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.60</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.77</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.001</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">EDE-Q global score</td>
                <td valign="top" align="left" rowspan="1" colspan="1">4.29</td>
                <td valign="top" align="left" rowspan="1" colspan="1">1.15</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.65</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.54</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.001</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">TAS-20 difficulty</td>
                <td valign="top" align="left" rowspan="1" colspan="1">22.78</td>
                <td valign="top" align="left" rowspan="1" colspan="1">5.88</td>
                <td valign="top" align="left" rowspan="1" colspan="1">11.46</td>
                <td valign="top" align="left" rowspan="1" colspan="1">4.74</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.001</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">identifying feelings</td>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">TAS-20 difficulty</td>
                <td valign="top" align="left" rowspan="1" colspan="1">17.96</td>
                <td valign="top" align="left" rowspan="1" colspan="1">3.36</td>
                <td valign="top" align="left" rowspan="1" colspan="1">10.50</td>
                <td valign="top" align="left" rowspan="1" colspan="1">4.08</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.001</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">describing feelings</td>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">TAS-20 externally</td>
                <td valign="top" align="left" rowspan="1" colspan="1">20.39</td>
                <td valign="top" align="left" rowspan="1" colspan="1">3.39</td>
                <td valign="top" align="left" rowspan="1" colspan="1">17.33</td>
                <td valign="top" align="left" rowspan="1" colspan="1">5.29</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.023</td>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">oriented thinking</td>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
                <td valign="top" align="left" rowspan="1" colspan="1"/>
              </tr>
              <tr>
                <td valign="top" align="left" rowspan="1" colspan="1">TAS-20 score</td>
                <td valign="top" align="left" rowspan="1" colspan="1">61.13</td>
                <td valign="top" align="left" rowspan="1" colspan="1">9.06</td>
                <td valign="top" align="left" rowspan="1" colspan="1">38.13</td>
                <td valign="top" align="left" rowspan="1" colspan="1">11.41</td>
                <td valign="top" align="left" rowspan="1" colspan="1">0.001</td>
              </tr>
            </tbody>
          </table>
          <table-wrap-foot>
            <attrib>
              <italic>AN, anorexia nervosa; HC, healthy control; Premorbid IQ, Standardized Wechsler Test of Adult Reading Score; BMI, body mass index; EDE-Q, Eating Disorders Examination Questionnaire; TAS-20, Toronto Alexithymia Scale; Age, age of illness onset and duration illness are reported in years.</italic>
            </attrib>
          </table-wrap-foot>
        </table-wrap>
      </sec>
      <sec>
        <title>Task</title>
        <p>Participants were presented with face stimuli from a standard set of black-and-white images, the Pictures of Facial Affect (<xref rid="B10" ref-type="bibr">Ekman et al., 1975</xref>). The stimuli consist of male and female images displaying the seven basic emotions: anger, disgust, fear, happiness, sadness, surprise, and neutral. The stimuli chosen were those with the highest inter-rater agreement for all seven emotions. Four male and four female models displaying each emotion were presented. Participants were first presented with an implicit task while undergoing fMRI and eyetracking, followed by the explicit task which involved emotion identification and eyetracking. An implicit task was undertaken during fMRI as explicit tasks have a higher cognitive demand and more frontal areas involvement, making it more difficult to observe activity in areas involved in emotion processing (<xref rid="B7" ref-type="bibr">Critchley et al., 2000</xref>; <xref rid="B16" ref-type="bibr">Gorno-Tempini et al., 2001</xref>). In the implicit task, participants were presented with each stimulus twice in a pseudorandom fashion, resulting in a total of 16 presentations of each emotion over two runs. In the explicit task, participants were shown each stimulus once, resulting in eight presentations per emotion over one run. Due to the extended length of the task in the MRI, participants were not presented with surprised faces in the implicit task as it is the most ambiguous emotion, having neither a positive or negative emotional valence. Participants were also pseudorandomly presented with a black-and-white image of their own face with a neutral expression, with 16 presentations during the implicit task and eight during the explicit task. Photographs of participants were taken by the researcher while participants were instructed to look straight ahead with a relaxed expression, similarly to a passport photograph. Participants’ own face photographs were edited to match the properties of the Ekman face stimuli in terms of size and resolution, and were made black-and-white.</p>
        <p>In the implicit task, faces were displayed pseudorandomly across emotions for 8000 ms on a white background, followed by a black 1° fixation cross for 3000–4300 ms. Each photograph was 336 × 640 pixels, equalling 17 cm × 27.5 cm or 18 × 13° at the eye. Participants were instructed simply to look at the face while it was on screen and to make a gender response with their right hand by clicking one of two buttons only when the fixation cross appeared following the face presentation. Long periods of fixation, between 10200 and 11400 ms were presented pseudorandomly throughout the task to increase BOLD signal variance by allowing the signal to return to baseline. Each of the two runs also began with a long period of fixation for 15000 ms.</p>
        <p>In the explicit task, faces were again displayed for 8000 ms on a white background, equalling to 8 × 13° to the eye. Prior to the presentation of each stimulus, a 1° fixation cross appeared in the center of the screen. Following the presentation of each face stimulus, a forced-choice screen appeared on the monitor asking participants to identify the emotion displayed in the previous face from a list containing all of the emotions. The participants were given as much time as they required to make a response.</p>
      </sec>
      <sec>
        <title>Data Acquisition and Analysis</title>
        <sec>
          <title>Eyetracking</title>
          <p>Stimuli were presented through SR Research’s Experiment Builder program, and eyetracking was recorded using a remote view eyetracker, the EyeLink1000 (SR Research, Mississauga, ON, Canada), monocularly at 500 Hz. The recorded data were analyzed with SR Research’s analysis program, DataViewer. Areas of interest (AOIs) were defined as the eyes, nose and mouth. To investigate the proportion of fixations and fixation durations to salient features and non-salient features, two spatial-temporal parameters were calculated: the feature fixation index (FFI) and the feature duration index (FDI; <xref rid="B48" ref-type="bibr">Williams et al., 1999</xref>). The FFI is derived by dividing the number of fixations to salient features minus the number of fixations to non-salient features by the total number of fixations. The FDI is derived in the same manner. Indices range from -1 to +1, with positive values indicating more fixations or longer durations to salient features, and negative values indicating more visual attention to non-salient features.</p>
        </sec>
        <sec>
          <title>Functional Magnetic Resonance Imaging</title>
          <p>Magnetic resonance imaging scans were undertaken with the Siemens Tim Trio 3 tesla system with a 32 channel head coil at Swinburne University of Technology (Melbourne, VIC, Australia). During each functional run of active task performance, 1080 T2<sup>∗</sup>-weighted images were acquired axially parallel to the AC–PC line using an interleaved multiband sequence (multiband acceleration factor = 4, bandwidth = 25988 Hz/Px, repetition time (TR) = 710 ms, echo-time (TE) = 30 ms, echo-spacing = 0.51 ms, flip-angle = 52°, field of view = 222 mm, voxel resolution = 3 mm × 3 mm × 3 mm, slice thickness = 3 mm, number of slices = 44). Multiband acquisition sequences were derived from the Human Connectome Project (<xref rid="B29" ref-type="bibr">Moeller et al., 2010</xref>). A T1-weighted image was acquired sagitally for anatomical reference (bandwidth = 170 Hz/Px, TR = 1900 ms, TE = 2.52 ms, echo spacing = 7.5 ms, flip angle = 9°, field-of-view = 350 mm × 263 mm × 350 mm, voxel resolution = 1 mm × 1 mm × 1 mm, slice thickness = 1 mm).</p>
          <p>Magnetic resonance imaging data pre-processing and statistical analyses were performed using SPM8, through Matlab R2014a (Mathworks, Natick, MA, USA). Image pre-processing included image realignment, then coregistration of the T1 image to a mean realigned functional image created during realignment. The co-registered T1 image was normalized to the T1 template supplied with SPM8 Montreal Neuroimaging Institute (MNI), then the parameters of this transformation were applied to realigned functional images. The normalized functional images were spatially smoothed with a Gaussian kernel of 8 mm × 8 mm × 8 mm.</p>
        </sec>
        <sec>
          <title>Statistical Analyses</title>
          <p>First-level modeling was performed by fitting a convolved hemodynamic response function (HRF) and its temporal derivative separately to the onset times of angry, disgusted, fearful, happy, sad, neutral, and own faces (seven regressors plus their temporal derivative). After parameter estimation, each emotion parameter and the participants’ own face parameter was contrasted with the neutral face parameter producing six contrast images (angry &gt; neutral, sad &gt; neutral, etc.). At the group level, these contrast images were first entered into one-way analysis of variance (ANOVA) models for AN and HC groups separately to investigate within-group effects (results are presented in Supplementary Material). Group differences were interrogated with a mixed-effects ANOVA model using the flexible factorial option in SPM8. This model included a between-subjects <italic>group</italic> factor (two levels: patients vs. controls), a within subjects <italic>condition</italic> factor (six levels: angry &gt; neutral, sad &gt; neutral, etc.) and a <italic>subject</italic>s factor (number of levels equals the number of participants) that controlled for within-subject variability (<xref rid="B15" ref-type="bibr">Gläscher and Gitelman, 2008</xref>).</p>
          <p><italic>T</italic>-statistic images were corrected for multiple comparisons using the random-field theory approach at the voxel and cluster levels (<italic>p</italic> &lt; 0.05, FWE-corrected). The mixed-design analysis involved the investigation of a group by condition interaction, followed by simple effects comparing each condition between groups.</p>
          <p>Following the mixed-design analysis, clusters which resulted in significant differences between groups were defined as different regions of interests (ROIs) with the MarsBar toolbox (<xref rid="B4" ref-type="bibr">Brett et al., 2002</xref>) run under Matlab R2014a. Contrast estimates for each ROI were correlated with eyetracking and behavioral data, and scores on the EDE-Q and TAS-20.</p>
          <p>Performance on eyetracking components and emotion identification (rate of emotion identification errors) were compared with mixed design ANOVAs, following normality checking and the removal of outliers. Percentage data underwent an arcsine transformation prior to inclusion in ANOVAs. Violations of sphericity were corrected with a Greenhouse–Geiser correction. For conditions in which groups significantly differed in emotion identification error rate, Mann–Whitney <italic>U</italic> tests were carried out to identify which emotions were incorrectly reported as the data were not normally distributed. Pearson’s correlation analyses were also performed between eyetracking data and behavioral data, and scores on the EDE-Q and TAS-20. For brevity, only significant interactions with group will be commented on in detail. Detailed results of eyetracking and fMRI analyses unrelated to group interactions are available as Supplementary Material.</p>
        </sec>
      </sec>
    </sec>
    <sec>
      <title>Results</title>
      <sec>
        <title>Behavioral</title>
        <p>For rate of emotion identification errors, a 2 (group) × 8 (condition) mixed design ANOVA was undertaken (see Supplementary Table <xref ref-type="supplementary-material" rid="SM1">S1</xref>). The analysis revealed a significant main effect of condition [<italic>F</italic>(2.5,113.5) = 7.4, <italic>p</italic> &lt; 0.001]. A significant main effect of group [<italic>F</italic>(1,46) = 5.2, <italic>p</italic> ≤ 0.05] and a significant interaction between group and condition were also found [<italic>F</italic>(2.5,113.5) = 4.6, <italic>p</italic> ≤ 0.01]. Within subjects contrasts revealed that groups did not significantly differ in emotion identification errors to any individual emotion, but AN participants made significantly more emotion identification errors to their own face [<italic>F</italic>(1,46) = 5.1, <italic>p</italic> ≤ 0.05]. When errors were made to own face emotion, analyses revealed that AN participants were more likely than controls to report their own face as sad [<italic>U</italic>(46) = 200.0, Z = -2.9, <italic>p</italic> ≤ 0.01], whereas control participants were more likely to correctly report their own neutral face as portraying a neutral expression [<italic>U</italic>(46) = 209.0, <italic>Z</italic> = -2.3, <italic>p</italic> ≤ 0.05] (see Supplementary Table <xref ref-type="supplementary-material" rid="SM1">S2</xref>).</p>
      </sec>
      <sec>
        <title>Eyetracking</title>
        <p>Average fixation count, fixation duration, and saccade amplitude were analyzed in separate 2 (group) × 7 (condition) × 2 (task) mixed design ANOVAs. As the first run of the fMRI task consisted of the same number of trials as the behavioral task, these two tasks were included in the analysis. Furthermore, as the behavioral task also consisted of surprised faces which were not included in the fMRI task, these trials were excluded from the analysis. Means and SD for fixation count, fixation duration and saccade amplitude are presented in see Supplementary Table <xref ref-type="supplementary-material" rid="SM1">S3</xref>.</p>
        <p>For fixation count, a significant main effect of condition [<italic>F</italic>(4.1,159.2) = 3.0, <italic>p</italic> ≤ 0.05] was found with a greater number of fixations made to participants’ own faces and faces depicting anger and fear. A significant main effect was also found for group [<italic>F</italic>(1,39) = 5.3, <italic>p</italic> ≤ 0.05], with AN participants making more fixations than controls. A significant interaction between condition and task was also found [<italic>F</italic>(3.4,131.9) = 7.61, <italic>p</italic> &lt; 0.001] with a decreased number of fixations between implicit and explicit tasks for participants’ own faces and faces depicting fear. There was, however, no significant main effect of task, and no significant interaction between condition and group, or task and group. There was also no interaction between condition, group and task. Analyses conducted on fixation duration revealed a significant main effect of group [<italic>F</italic>(1,38) = 8.5, <italic>p</italic> ≤ 0.01] with AN participants making fixations of shorter duration than heathy individuals. No other significant main effects or interactions were found. Analyses conducted on saccade amplitude resulted in no significant main effects or interactions.</p>
        <p>A 2 (group) × 7 (condition) × 2 (task) mixed design ANOVA conducted on the FDI revealed a significant main effect of condition [<italic>F</italic>(2.3,82.0) = 16.4, <italic>p</italic> &lt; 0.001], and a significant interaction between condition and task [<italic>F</italic>(4.0,144.9) = 3.0, <italic>p</italic> ≤ 0.05] with greater attention to salient features of one’s own face during the implicit compared to explicit task. Analyses conducted on the FFI revealed significant main effects of condition [<italic>F</italic>(2.2,72.5) = 19.7, <italic>p</italic> &lt; 0.001] and task [<italic>F</italic>(1,33) = 10.1, <italic>p</italic> ≤ 0.01] with greater attention to salient facial features during the explicit task compared to the implicit task. Significant interactions were also found between condition and task [<italic>F</italic>(3.8,125.9) = 3.1, <italic>p</italic> ≤ 0.05] and condition and group [<italic>F</italic>(2.2,72.5) = 3.2, <italic>p</italic> ≤ 0.05]. Within-subjects contrasts did not reveal any significant differences between groups for any emotion, but a significant difference for own faces between AN and control participants [<italic>F</italic>(1,33) = 5.9, <italic>p</italic> ≤ 0.05]. Further 2 (group) × 2 (task) mixed design ANOVAs were also conducted on the FFI and FDI to participants’ own face. A significant main effect of task, and an interaction between task and group were not found for either the FFI or FDI. A significant main effect of group was, however, found for both the FFI [<italic>F</italic>(1,36) = 7.6, <italic>p</italic> &gt; 0.01] and FDI [<italic>F</italic>(1,36) = 6.8, <italic>p</italic> ≤ 0.05] (see Supplementary Table <xref ref-type="supplementary-material" rid="SM1">S4</xref>). Control participants showed more visual attention to salient features of their own face, whereas the attention shown to salient and non-salient features of their own face in AN was roughly equal.</p>
      </sec>
      <sec>
        <title>Functional Magnetic Resonance Imaging</title>
        <sec>
          <title>Mixed Design Analysis</title>
          <p>The analysis did not result in a significant group by condition interaction. Simple effects between groups for each condition revealed a significant difference between groups only for the own &gt; neutral face contrast. Increased activation was found in AN compared to controls in the own &gt; neutral contrast in two clusters: one in the right inferior temporal and middle temporal gyri, and one in the right lingual gyrus (<bold>Table <xref ref-type="table" rid="T2">2</xref></bold>; <bold>Figure <xref ref-type="fig" rid="F1">1</xref></bold>).</p>
          <fig id="F1" position="float">
            <label>FIGURE 1</label>
            <caption>
              <p><bold>Increased activity in the anorexia nervosa (AN) group compared to the control group in the right inferior and middle temporal gyri <bold>(A)</bold>, and the right lingual gyrus <bold>(B)</bold> for participants’ own faces compared to neutral faces (contrast: AN &gt; controls, own &gt; neutral face; FWE-corrected for multiple comparisons at the voxel and cluster levels).</bold> The color scale indicates the <italic>t</italic>-value.</p>
            </caption>
            <graphic xlink:href="fpsyg-06-01181-g001"/>
          </fig>
          <table-wrap id="T2" position="float">
            <label>Table 2</label>
            <caption>
              <p>Significant activations for participants’ own faces compared to neutral faces between anorexia nervosa (AN) and control participants, Own &gt; Neutral, AN &gt; Healthy Controls.</p>
            </caption>
            <table frame="hsides" rules="groups" cellspacing="5" cellpadding="5">
              <thead>
                <tr>
                  <th valign="top" align="left" rowspan="1" colspan="1">Peak regions</th>
                  <th valign="top" align="left" rowspan="1" colspan="1">No. of voxels</th>
                  <th valign="top" align="left" rowspan="1" colspan="1">Peak <italic>t</italic></th>
                  <th valign="top" align="center" colspan="3" rowspan="1">Peak MNI coordinates<hr/></th>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1"/>
                  <td valign="top" align="left" rowspan="1" colspan="1"/>
                  <td valign="top" align="left" rowspan="1" colspan="1"/>
                  <th valign="top" align="left" rowspan="1" colspan="1">
                    <italic>x</italic>
                  </th>
                  <th valign="top" align="left" rowspan="1" colspan="1">
                    <italic>y</italic>
                  </th>
                  <th valign="top" align="left" rowspan="1" colspan="1">
                    <italic>z</italic>
                  </th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Inferior temporal gyrus</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">104</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">6.45</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">50</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">-54</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">-4</td>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">middle temporal gyrus</td>
                  <td valign="top" align="left" rowspan="1" colspan="1"/>
                  <td valign="top" align="left" rowspan="1" colspan="1"/>
                  <td valign="top" align="left" rowspan="1" colspan="1"/>
                  <td valign="top" align="left" rowspan="1" colspan="1"/>
                  <td valign="top" align="left" rowspan="1" colspan="1"/>
                </tr>
                <tr>
                  <td valign="top" align="left" rowspan="1" colspan="1">Lingual gyrus</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">118</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">5.37</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">28</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">-88</td>
                  <td valign="top" align="left" rowspan="1" colspan="1">-8</td>
                </tr>
              </tbody>
            </table>
            <table-wrap-foot>
              <attrib>
                <italic>MNI, Montreal Neuroimaging Institute.</italic>
              </attrib>
            </table-wrap-foot>
          </table-wrap>
        </sec>
      </sec>
      <sec>
        <title>Pearson’s Correlations</title>
        <p>BOLD activity in the own &gt; neutral face contrast in either the inferior and middle temporal gyri ROI, or the lingual gyrus ROI did not significantly correlate with any eyetracking parameter, rate of emotion identification errors, or the results of the EDE-Q and TAS-20 for either group. Eyetracking and behavioral data, and scores on the EDE-Q and TAS-20 were also not found to correlate with one another.</p>
      </sec>
    </sec>
    <sec>
      <title>Discussion</title>
      <p>The aim of this study was to investigate own face processing and the processing of emotional faces of others, in individuals with AN. Although the AN group were found to have higher alexithymia scores, they did not differ from healthy controls in emotion identification of the Ekman emotional face stimuli. Groups were found to differ in visual scanpath behavior to the stimuli in general, with AN participants demonstrating hyperscanning, evinced by increased fixations of shorter duration, relative to controls. AN participants were also found to avoid visually attending to salient features of their own face and displayed increased activity in the right lingual, and inferior and middle temporal gyri to images of their own face, compared to neutral control images, as well as to healthy individuals.</p>
      <p>In analyses directly comparing AN to healthy individuals, AN participants showed increased activity to their own face in the right inferior and middle temporal gyri, and lingual gyrus, areas related to higher-order visual perception. Increased activity of the lingual gyrus has been reported during the processing of human faces (<xref rid="B21" ref-type="bibr">Kesler/West et al., 2001</xref>), and increased activity in the inferior and middle temporal gyri have been specifically found in response to own face stimuli (<xref rid="B23" ref-type="bibr">Kircher et al., 2001</xref>; <xref rid="B32" ref-type="bibr">Platek et al., 2006</xref>; <xref rid="B39" ref-type="bibr">Sugiura et al., 2008</xref>). Therefore, the findings of the current study suggest an increased processing of own face stimuli in AN in areas related to visual perception of self.</p>
      <p>Differences in lingual gyrus and temporal gyrus activity have also been reported when individuals with AN are presented with images of their own body compared to other individuals’ bodies. However, increased activity in these areas was found for controls relative to AN participants (<xref rid="B36" ref-type="bibr">Sachdev et al., 2008</xref>; <xref rid="B44" ref-type="bibr">Vocks et al., 2010</xref>), rather than increased activity in AN as found in the current study. However, neither of those studies actually involved face processing; rather, the faces of the stimuli presented in those studies were masked when presented to participants. Therefore, the differences in activation between the current findings and the findings of these two studies may be related to the specific processing of self-face and self-body images which result in increased activity and decreased activity in these areas in AN respectively.</p>
      <p>Our AN group also showed more visual attention to non-salient features and avoided fixating on salient features of their own face. <xref rid="B13" ref-type="bibr">Freeman et al. (1991)</xref> reported that when AN participants were presented with whole body images of themselves, less visual attention was allocated to their faces compared to controls, though the level of visual attention to different body areas did not differ. Furthermore, <xref rid="B14" ref-type="bibr">Giel et al. (2011)</xref> reported a similar pattern of visual attention in a study which presented AN and control participants with food and non-food images simultaneously: although healthy individuals showed more visual attention to food stimuli, the AN group displayed roughly equal attention to food and non-food stimuli. These results may be related to the finding that decreased visual attention is associated with the presentation of anxiety-inducing and phobic stimuli. Similarly to the current findings, <xref rid="B18" ref-type="bibr">Horley et al. (2003)</xref> reported that individuals with social anxiety disorder made fixations of short duration to salient features of emotional faces stimuli. <xref rid="B31" ref-type="bibr">Pflugshaupt et al. (2007)</xref>, reported that individuals with spider phobia displayed fewer fixations to spider images and instead diverted their attention to neutral areas of the stimulus. The authors described this behavior as a strategy to cope with threatening and confrontational stimuli, to consequently reduce anxiety. Individuals with AN may utilize similar strategies when viewing their own face as they may find these stimuli anxiety-provoking. An avoidance of salient features was not, however, found to the Ekman face stimuli, suggesting that this behavior is specific to one’s own face.</p>
      <p>Hyperscanning of face stimuli (increased fixations of shorter duration) was also found in our AN group, though this was not specific to self-face images. Hyperscanning behaviors are associated with increased anxiety, as has been reported in social anxiety disorder to face stimuli of different emotions (<xref rid="B18" ref-type="bibr">Horley et al., 2003</xref>). <xref rid="B18" ref-type="bibr">Horley et al. (2003)</xref> suggested the hyperscanning behavior in social anxiety disorder may reflect a fear of social evaluation. This explanation may also be relevant to the current findings: due to a preoccupation with physical appearance, individuals with AN are particularly sensitive to social evaluations made by others (<xref rid="B38" ref-type="bibr">Striegel-Moore et al., 1993</xref>) and may show increased scanning behaviors to related stimuli.</p>
      <p>Despite previous reports of emotion identification deficits in individuals with AN, our findings do not concur. Although higher levels of alexithymia were found in the AN group, the ability to identify emotions from a standard set of face stimuli did not differ from healthy individuals. This finding is consistent with the literature which suggests that alexithymia levels are not related to the ability to perceive emotion from faces (see <xref rid="B17" ref-type="bibr">Grynbergs et al., 2012</xref> for a review). However, whether high alexithymia impairs the ability to perceive emotion in an image of one’s own face has not been investigated, nor was it specifically investigated in this study, as we only presented participants with own-face images showing a neutral expression. Although the majority of AN participants reported their own face as portraying a neutral expression, they were more likely than controls to report their own face as depicting a sad expression. However, rather than indicating an emotion identification deficit specific to themselves, this result is more likely to reflect a biased self-perception in how individuals with AN <italic>feel</italic> they look. Thus, when identification errors occurred as they viewed their own faces, they were specific to seeing themselves as sad and not any other emotions. Furthermore, when participants were questioned following the task about their overall experience, the controls often reported that they found it ‘funny’ looking at their own face, whereas AN patients tended to feel disgusted.</p>
      <p>Though AN and control participants differed in the processing of their own face, we found no differences in BOLD activity in response to different emotions, in either group. As strict thresholding was utilized in an attempt to correct for multiple comparisons, the task may not have had sufficient power to document significant differences in activation of each emotion relative to the neutral face condition. However, as the contrasts between participants’ own face and the neutral face condition survived this threshold, the results show that BOLD activity elicited in response to the different emotions was not as strong. Since we were interested in assessing the visual scanpaths of AN patients to face stimuli, the extended presentation time was required for this purpose and the number of trials was therefore limited to remain within a reasonable duration for an MRI task. In future research, where visual scanpaths are not of interest, an increased number of trials should be utilized. It would also be of interest to investigate differences in visual scanpaths and neural activity to both own-face and own-body stimuli in AN, and an evaluation of how these images make AN patients feel.</p>
      <p>The findings of this study have important potential clinical implications. Participants with AN did not differ from healthy control participants in the areas of attentional focus when viewing the Ekman face stimuli, nor did they differ in emotion identification of these stimuli. AN participants did, however, display an avoidance of salient features of images of their own faces. This may have consequently led to the mislabelling of their own neutral expression as sad. In other words, the perception of one’s own face with a neutral expression as appearing sad in AN may be related to patients not looking at the correct areas of their own face when making an affect judgment. This may be as a result of emotional disturbances and alexithymia in AN, or this alternatively may lead to these disturbances. Therefore, remediation techniques which train participants to focus on the correct areas of the face may be beneficial in AN. These techniques have proven useful in other psychiatric conditions such as schizophrenia, with trained individuals demonstrating an improvement in attention to salient facial features and emotion recognition (<xref rid="B35" ref-type="bibr">Russell et al., 2008</xref>; <xref rid="B27" ref-type="bibr">Marsh et al., 2012</xref>). Furthermore, the majority of deficits reported in the current study were specific to the processing of self-images in AN. This emphasizes the importance of therapies such as cognitive behavioral therapy to address distorted perceptions of oneself in AN and correctly analyzing events and the patient’s own internal dialog. It is also possible that the sense of disgust evoked by viewing their own face also reduced the AN group’s fixations on the salient regions of images of their own faces, in the way that one might avoid eye contact with a repellent individual.</p>
      <p>In summary, this study suggests intact emotion identification of facial affect stimuli and distinct hyperscanning behaviors when viewing faces in AN. Significant differences were also found in the processing of one’s own face in AN, with AN participants showing a greater level of visual attention to non-salient features and increased activity in inferior and middle temporal, and lingual gyri, relative to healthy individuals. These findings suggest overlap with anxiety disorders, as evinced by the hyperscanning behaviors displayed, and increased anxiety, particularly to own face images evinced by an apparent avoidance of salient features. Together with the fMRI finding, the study suggests that the processing of self-face images is different in AN, and may contribute to the distorted perception of oneself experienced by individuals with this illness.</p>
    </sec>
    <sec>
      <title>Author Contributions</title>
      <p>AP, LA, SR, CG, and DC designed the research; AP completed data collection; all authors were involved in data analysis and manuscript preparation.</p>
    </sec>
    <sec>
      <title>Conflict of Interest Statement</title>
      <p>Prof. David J. Castle reports grants and personal fees from Eli Lilly, grants and personal fees from Janssen-Cilag, grants and personal fees from Roche, grants and personal fees from Allergen, grants and personal fees from Bristol-Myer Squibb, grants and personal fees from Pfizer, grants and personal fees from Lundbeck, grants and personal fees from AstraZeneca, grants and personal fees from Hospira, during the conduct of the study; personal fees from Eli Lilly, personal fees from Bristol-Myer Squibb, personal fees from Lundbeck, personal fees from Janssen-Cilag, personal fees from Pfizer, personal fees from Organon, personal fees from Sanofi-Aventis, personal fees from Wyeth, personal fees from Hospira, personal fees from Servier, outside the submitted work. Prof. Larry A. Abel reports personal fees from Actelion Pharmaceuticals, Switzerland, outside the submitted work. Dr. Andrea Phillipou, Prof. Susan L. Rossell, Dr. Caroline Gurvich, Dr. Matthew E. Hughes, and Mr. Richard G. Nibbs report no conflicts of interest.</p>
    </sec>
  </body>
  <back>
    <ack>
      <p>This research was supported by the Jack Brockhoff Foundation (LA, SR, DC, AP, grant number: 3410); the Dick and Pip Smith Foundation (AP, LA, SR, DC); an Australian Postgraduate Award (AP) and the David Hay Memorial Fund Award (AP). The authors would like to thank Charlotte Keating for administering the clinical interview. The authors would also like to thank Chia Huang, Richard Newton, Lynley Gervasoni, Michelle Snell, Helen Shepherd, Philippa Harrison, and Felicity Lawrence for their assistance in recruiting participants. Finally, the authors would like to thank everyone who took the time to participate in the study.</p>
    </ack>
    <sec sec-type="supplementary material">
      <title>Supplementary Material</title>
      <p>The Supplementary Material for this article can be found online at: <ext-link ext-link-type="uri" xlink:href="http://journal.frontiersin.org/article/10.3389/fpsyg.2015.01181">http://journal.frontiersin.org/article/10.3389/fpsyg.2015.01181</ext-link></p>
      <supplementary-material content-type="local-data" id="SM1">
        <media xlink:href="Data_Sheet_1.DOCX">
          <caption>
            <p>Click here for additional data file.</p>
          </caption>
        </media>
      </supplementary-material>
    </sec>
    <ref-list>
      <title>References</title>
      <ref id="B1">
        <mixed-citation publication-type="book"><collab>American Psychiatric Association.</collab> (<year>2013</year>). <source><italic>Diagnostic and Statistical Manual of Mental Disorders 5.</italic></source>
<publisher-loc>Washington, DC</publisher-loc>: <publisher-name>American Psychiatric Association</publisher-name>.</mixed-citation>
      </ref>
      <ref id="B2">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bagby</surname><given-names>R. M.</given-names></name><name><surname>Parker</surname><given-names>J. D. A.</given-names></name><name><surname>Taylor</surname><given-names>G. J.</given-names></name></person-group> (<year>1994</year>). <article-title>The twenty-item Toronto Alexithymia Scale—I. Item selection and cross-validation of the factor structure.</article-title>
<source><italic>J. Psychosom. Res.</italic></source>
<volume>38</volume>
<fpage>23</fpage>–<lpage>32</lpage>.<pub-id pub-id-type="pmid">8126686</pub-id></mixed-citation>
      </ref>
      <ref id="B3">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bourke</surname><given-names>M. P.</given-names></name><name><surname>Taylor</surname><given-names>G. J.</given-names></name><name><surname>Parker</surname><given-names>J. D.</given-names></name><name><surname>Bagby</surname><given-names>R. M.</given-names></name></person-group> (<year>1992</year>). <article-title>Alexithymia in women with anorexia nervosa. A preliminary investigation.</article-title>
<source><italic>Br. J. Psychiatry</italic></source>
<volume>161</volume>
<fpage>240</fpage>–<lpage>243</lpage>.<pub-id pub-id-type="pmid">1521107</pub-id></mixed-citation>
      </ref>
      <ref id="B4">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brett</surname><given-names>M.</given-names></name><name><surname>Anton</surname><given-names>J.-L.</given-names></name><name><surname>Valabregue</surname><given-names>R.</given-names></name><name><surname>Poline</surname><given-names>J.-B.</given-names></name></person-group> (<year>2002</year>). <article-title>Region of interest analysis using the MarsBar toolbox for SPM 99.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>16</volume>
<issue>S497</issue>.</mixed-citation>
      </ref>
      <ref id="B5">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bruch</surname><given-names>H.</given-names></name></person-group> (<year>1962</year>). <article-title>Perceptual and conceptual disturbances in anorexia nervosa.</article-title>
<source><italic>Psychosom. Med.</italic></source>
<volume>21</volume>
<fpage>187</fpage>–<lpage>194</lpage>. <pub-id pub-id-type="doi">10.1097/00006842-196203000-00009</pub-id><pub-id pub-id-type="pmid">13873828</pub-id></mixed-citation>
      </ref>
      <ref id="B6">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cowdrey</surname><given-names>F. A.</given-names></name><name><surname>Harmer</surname><given-names>C. J.</given-names></name><name><surname>Park</surname><given-names>R. J.</given-names></name><name><surname>Mccabe</surname><given-names>C.</given-names></name></person-group> (<year>2012</year>). <article-title>Neural responses to emotional faces in women recovered from anorexia nervosa.</article-title>
<source><italic>Psychiatry Res.</italic></source>
<volume>201</volume>
<fpage>190</fpage>–<lpage>195</lpage>. <pub-id pub-id-type="doi">10.1016/j.pscychresns.2011.08.009</pub-id><pub-id pub-id-type="pmid">22464825</pub-id></mixed-citation>
      </ref>
      <ref id="B7">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Critchley</surname><given-names>H.</given-names></name><name><surname>Daly</surname><given-names>E.</given-names></name><name><surname>Phillips</surname><given-names>M.</given-names></name><name><surname>Brammer</surname><given-names>M.</given-names></name><name><surname>Bullmore</surname><given-names>E.</given-names></name><name><surname>Williams</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2000</year>). <article-title>Explicit and implicit neural mechanisms for processing of social information from facial expressions: a functional magnetic resonance imaging study.</article-title>
<source><italic>Hum. Brain Mapp.</italic></source>
<volume>9</volume>
<fpage>93</fpage>–<lpage>105</lpage>. <pub-id pub-id-type="doi">10.1002/(SICI)1097-0193(200002)9:2&lt;93::AID-HBM4&gt;3.3.CO;2-Q</pub-id><pub-id pub-id-type="pmid">10680766</pub-id></mixed-citation>
      </ref>
      <ref id="B8">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Delerue</surname><given-names>C.</given-names></name><name><surname>Laprévote</surname><given-names>V.</given-names></name><name><surname>Verfaillie</surname><given-names>K.</given-names></name><name><surname>Boucart</surname><given-names>M.</given-names></name></person-group> (<year>2010</year>). <article-title>Gaze control during face exploration in schizophrenia.</article-title>
<source><italic>Neurosci. Lett.</italic></source>
<volume>482</volume>
<fpage>245</fpage>–<lpage>249</lpage>. <pub-id pub-id-type="doi">10.1016/j.neulet.2010.07.048</pub-id><pub-id pub-id-type="pmid">20667499</pub-id></mixed-citation>
      </ref>
      <ref id="B9">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>De Wit</surname><given-names>T. C. J.</given-names></name><name><surname>Falck-Ytter</surname><given-names>T.</given-names></name><name><surname>Von Hofsten</surname><given-names>C.</given-names></name></person-group> (<year>2008</year>). <article-title>Young children with autism spectrum disorder look differently at positive versus negative emotional faces.</article-title>
<source><italic>Res. Autism Spectr. Disord.</italic></source>
<volume>2</volume>
<fpage>651</fpage>–<lpage>659</lpage>. <pub-id pub-id-type="doi">10.1016/j.rasd.2008.01.004</pub-id></mixed-citation>
      </ref>
      <ref id="B10">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ekman</surname><given-names>P.</given-names></name><name><surname>Friesen</surname><given-names>W. V.</given-names></name><name><surname>Press</surname><given-names>C. P.</given-names></name></person-group> (<year>1975</year>). <source><italic>Pictures of Facial Affect.</italic></source>
<publisher-loc>Palo Alto, CA</publisher-loc>: <publisher-name>Consulting Psychologists Press</publisher-name>.</mixed-citation>
      </ref>
      <ref id="B11">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fairburn</surname><given-names>C. G.</given-names></name></person-group> (<year>2008</year>). <source><italic>Cognitive Behavior Therapy and Eating Disorders.</italic></source>
<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Guilford Press</publisher-name>.</mixed-citation>
      </ref>
      <ref id="B12">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fonville</surname><given-names>L.</given-names></name><name><surname>Giampietro</surname><given-names>V.</given-names></name><name><surname>Surguladze</surname><given-names>S.</given-names></name><name><surname>Williams</surname><given-names>S.</given-names></name><name><surname>Tchanturia</surname><given-names>K.</given-names></name></person-group> (<year>2014</year>). <article-title>Increased BOLD signal in the fusiform gyrus during implicit emotion processing in anorexia nervosa.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>4</volume>
<fpage>266</fpage>–<lpage>273</lpage>. <pub-id pub-id-type="doi">10.1016/j.nicl.2013.12.002</pub-id><pub-id pub-id-type="pmid">24501698</pub-id></mixed-citation>
      </ref>
      <ref id="B13">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Freeman</surname><given-names>R.</given-names></name><name><surname>Touyz</surname><given-names>S.</given-names></name><name><surname>Sara</surname><given-names>G.</given-names></name><name><surname>Rennie</surname><given-names>C.</given-names></name><name><surname>Gordon</surname><given-names>E.</given-names></name><name><surname>Beumont</surname><given-names>P.</given-names></name></person-group> (<year>1991</year>). <article-title>In the eye of the beholder: processing body shape information in anorexic and bulimic patients.</article-title>
<source><italic>Int. J. Eat. Disord.</italic></source>
<volume>10</volume>
<fpage>709</fpage>–<lpage>714</lpage>. <pub-id pub-id-type="doi">10.1002/1098-108X(199111)10:6&lt;709::AID-EAT2260100609&gt;3.0.CO;2-N</pub-id></mixed-citation>
      </ref>
      <ref id="B14">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Giel</surname><given-names>K. E.</given-names></name><name><surname>Friederich</surname><given-names>H.</given-names></name><name><surname>Teufel</surname><given-names>M.</given-names></name><name><surname>Hautzinger</surname><given-names>M.</given-names></name><name><surname>Enck</surname><given-names>P.</given-names></name><name><surname>Zipfel</surname><given-names>S.</given-names></name></person-group> (<year>2011</year>). <article-title>Attentional processing of food pictures in individuals with anorexia nervosa–an eye-tracking study.</article-title>
<source><italic>Biol. Psychiatry</italic></source>
<volume>69</volume>
<fpage>661</fpage>–<lpage>667</lpage>. <pub-id pub-id-type="doi">10.1016/j.biopsych.2010.09.047</pub-id><pub-id pub-id-type="pmid">21109232</pub-id></mixed-citation>
      </ref>
      <ref id="B15">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gläscher</surname><given-names>J.</given-names></name><name><surname>Gitelman</surname><given-names>D.</given-names></name></person-group> (<year>2008</year>). <source><italic>Contrast Weights in Flexible Factorial Design with Multiple Groups of Subjects [Online].</italic></source> Available at: <ext-link ext-link-type="uri" xlink:href="http://www.google.com.au/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0CB0QFjAA&amp;url=http%3A%2F%2Fbrainimaging.waisman.wisc.edu%2F~jjo%2Fdownloads%2Fcontrasts_groups_glascher_2008.pdf&amp;ei=O3p-VKahDePMmwWq2IGwAQ&amp;usg=AFQjCNHlSew8P1gGRECXP8JofomdZXHqAg&amp;sig2=N0w2tdbJ9UqAMZzfVRdhLQ">http://www.google.com.au/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=1&amp;ved=0CB0QFjAA&amp;url=http%3A%2F%2Fbrainimaging.waisman.wisc.edu%2F~jjo%2Fdownloads%2Fcontrasts_groups_glascher_2008.pdf&amp;ei=O3p-VKahDePMmwWq2IGwAQ&amp;usg=AFQjCNHlSew8P1gGRECXP8JofomdZXHqAg&amp;sig2=N0w2tdbJ9UqAMZzfVRdhLQ</ext-link></mixed-citation>
      </ref>
      <ref id="B16">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gorno-Tempini</surname><given-names>M. L.</given-names></name><name><surname>Pradelli</surname><given-names>S.</given-names></name><name><surname>Serafini</surname><given-names>M.</given-names></name><name><surname>Pagnoni</surname><given-names>G.</given-names></name><name><surname>Baraldi</surname><given-names>P.</given-names></name><name><surname>Porro</surname><given-names>C.</given-names></name><etal/></person-group> (<year>2001</year>). <article-title>Explicit and incidental facial expression processing: an fMRI study.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>14</volume>
<fpage>465</fpage>–<lpage>473</lpage>.<pub-id pub-id-type="pmid">11467919</pub-id></mixed-citation>
      </ref>
      <ref id="B17">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Grynbergs</surname><given-names>D.</given-names></name><name><surname>Chang</surname><given-names>B.</given-names></name><name><surname>Corneille</surname><given-names>O.</given-names></name><name><surname>Maurage</surname><given-names>P.</given-names></name><name><surname>Vermeulen</surname><given-names>N.</given-names></name><name><surname>Berthoz</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>Alexithymia and the processing of emotional facial expressions (EFEs): systematic review, unanswered questions and further perspectives.</article-title>
<source><italic>PLoS ONE</italic></source>
<volume>7</volume>:<issue>e42429</issue>
<pub-id pub-id-type="doi">10.1371/journal.pone.0042429</pub-id></mixed-citation>
      </ref>
      <ref id="B18">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horley</surname><given-names>K.</given-names></name><name><surname>Williams</surname><given-names>L. M.</given-names></name><name><surname>Gonsalvez</surname><given-names>C.</given-names></name><name><surname>Gordon</surname><given-names>E.</given-names></name></person-group> (<year>2003</year>). <article-title>Social phobics do not see eye to eye: a visual scanpath study of emotional expression processing.</article-title>
<source><italic>J. Anxiety Disord.</italic></source>
<volume>17</volume>
<fpage>33</fpage>–<lpage>44</lpage>. <pub-id pub-id-type="doi">10.1016/S0887-6185(02)00180-9</pub-id><pub-id pub-id-type="pmid">12464287</pub-id></mixed-citation>
      </ref>
      <ref id="B19">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jänsch</surname><given-names>C.</given-names></name><name><surname>Harmer</surname><given-names>C.</given-names></name><name><surname>Cooper</surname><given-names>M. J.</given-names></name></person-group> (<year>2009</year>). <article-title>Emotional processing in women with anorexia nervosa and in healthy volunteers.</article-title>
<source><italic>Eat. Behav.</italic></source>
<volume>10</volume>
<fpage>184</fpage>–<lpage>191</lpage>. <pub-id pub-id-type="doi">10.1016/j.eatbeh.2009.06.001</pub-id><pub-id pub-id-type="pmid">19665102</pub-id></mixed-citation>
      </ref>
      <ref id="B20">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaye</surname><given-names>W. H.</given-names></name><name><surname>Bulik</surname><given-names>C. M.</given-names></name><name><surname>Thornton</surname><given-names>L.</given-names></name><name><surname>Barbarich</surname><given-names>N.</given-names></name><name><surname>Masters</surname><given-names>K.</given-names></name></person-group> (<year>2004</year>). <article-title>Comorbidity of anxiety disorders with anorexia and bulimia nervosa.</article-title>
<source><italic>Am. J. Psychiatry</italic></source>
<volume>161</volume>
<fpage>2215</fpage>–<lpage>2221</lpage>. <pub-id pub-id-type="doi">10.1176/appi.ajp.161.12.2215</pub-id><pub-id pub-id-type="pmid">15569892</pub-id></mixed-citation>
      </ref>
      <ref id="B21">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kesler/West</surname><given-names>M. L.</given-names></name><name><surname>Andersen</surname><given-names>A. H.</given-names></name><name><surname>Smith</surname><given-names>C. D.</given-names></name><name><surname>Avison</surname><given-names>M. J.</given-names></name><name><surname>Davis</surname><given-names>C. E.</given-names></name><name><surname>Kryscio</surname><given-names>R. J.</given-names></name><etal/></person-group> (<year>2001</year>). <article-title>Neural substrates of facial emotion processing using fMRI.</article-title>
<source><italic>Cogn. Brain Res.</italic></source>
<volume>11</volume>
<fpage>213</fpage>–<lpage>226</lpage>. <pub-id pub-id-type="doi">10.1016/S0926-6410(00)00073-2</pub-id></mixed-citation>
      </ref>
      <ref id="B22">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kessler</surname><given-names>H.</given-names></name><name><surname>Schwarze</surname><given-names>M.</given-names></name><name><surname>Filipic</surname><given-names>S.</given-names></name><name><surname>Traue</surname><given-names>H. C.</given-names></name><name><surname>Von Wietersheim</surname><given-names>J.</given-names></name></person-group> (<year>2006</year>). <article-title>Alexithymia and facial emotion recognition in patients with eating disorders.</article-title>
<source><italic>Int. J. Eat. Disord.</italic></source>
<volume>39</volume>
<fpage>245</fpage>–<lpage>251</lpage>. <pub-id pub-id-type="doi">10.1002/eat.20228</pub-id><pub-id pub-id-type="pmid">16485269</pub-id></mixed-citation>
      </ref>
      <ref id="B23">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kircher</surname><given-names>T. T. J.</given-names></name><name><surname>Senior</surname><given-names>C.</given-names></name><name><surname>Phillips</surname><given-names>M. L.</given-names></name><name><surname>Rabe-Hesketh</surname><given-names>S.</given-names></name><name><surname>Benson</surname><given-names>P. J.</given-names></name><name><surname>Bullmore</surname><given-names>E. T.</given-names></name><etal/></person-group> (<year>2001</year>). <article-title>Recognizing one’s own face.</article-title>
<source><italic>Cognition</italic></source>
<volume>78</volume>
<fpage>B1</fpage>–<lpage>B15</lpage>. <pub-id pub-id-type="doi">10.1016/S0010-0277(00)00104-9</pub-id><pub-id pub-id-type="pmid">11062324</pub-id></mixed-citation>
      </ref>
      <ref id="B24">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kucharska-Pietura</surname><given-names>K.</given-names></name><name><surname>Nikolaou</surname><given-names>V.</given-names></name><name><surname>Masiak</surname><given-names>M.</given-names></name><name><surname>Treasure</surname><given-names>J.</given-names></name></person-group> (<year>2004</year>). <article-title>The recognition of emotion in the faces and voice of anorexia nervosa.</article-title>
<source><italic>Int. J. Eat. Disord.</italic></source>
<volume>35</volume>
<fpage>42</fpage>–<lpage>47</lpage>. <pub-id pub-id-type="doi">10.1002/eat.10219</pub-id><pub-id pub-id-type="pmid">14705156</pub-id></mixed-citation>
      </ref>
      <ref id="B25">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Legenbauer</surname><given-names>T.</given-names></name><name><surname>Vocks</surname><given-names>S.</given-names></name><name><surname>Rüddel</surname><given-names>H.</given-names></name></person-group> (<year>2008</year>). <article-title>Emotion recognition, emotional awareness and cognitive bias in individuals with bulimia nervosa.</article-title>
<source><italic>J. Clin. Psychol.</italic></source>
<volume>64</volume>
<fpage>687</fpage>–<lpage>702</lpage>. <pub-id pub-id-type="doi">10.1002/jclp.20483</pub-id><pub-id pub-id-type="pmid">18473338</pub-id></mixed-citation>
      </ref>
      <ref id="B26">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Loughland</surname><given-names>C. M.</given-names></name><name><surname>Williams</surname><given-names>L. M.</given-names></name><name><surname>Gordon</surname><given-names>E.</given-names></name></person-group> (<year>2002</year>). <article-title>Visual scanpaths to positive and negative facial emotions in an outpatient schizophrenia sample.</article-title>
<source><italic>Schizophr. Res.</italic></source>
<volume>55</volume>
<fpage>159</fpage>–<lpage>170</lpage>. <pub-id pub-id-type="doi">10.1016/S0920-9964(01)00186-4</pub-id><pub-id pub-id-type="pmid">11955975</pub-id></mixed-citation>
      </ref>
      <ref id="B27">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Marsh</surname><given-names>P. J.</given-names></name><name><surname>Luckett</surname><given-names>G.</given-names></name><name><surname>Russell</surname><given-names>T.</given-names></name><name><surname>Coltheart</surname><given-names>M.</given-names></name><name><surname>Green</surname><given-names>M. J.</given-names></name></person-group> (<year>2012</year>). <article-title>Effects of facial emotion recognition remediation on visual scanning of novel face stimuli.</article-title>
<source><italic>Schizophr. Res.</italic></source>
<volume>141</volume>
<fpage>234</fpage>–<lpage>240</lpage>. <pub-id pub-id-type="doi">10.1016/j.schres.2012.08.006</pub-id><pub-id pub-id-type="pmid">22959743</pub-id></mixed-citation>
      </ref>
      <ref id="B28">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mendlewicz</surname><given-names>L.</given-names></name><name><surname>Linkowski</surname><given-names>P.</given-names></name><name><surname>Bazelmans</surname><given-names>C.</given-names></name><name><surname>Philippot</surname><given-names>P.</given-names></name></person-group> (<year>2005</year>). <article-title>Decoding emotional facial expressions in depressed and anorexic patients.</article-title>
<source><italic>J. Affect. Disord.</italic></source>
<volume>89</volume>
<fpage>195</fpage>–<lpage>199</lpage>. <pub-id pub-id-type="doi">10.1016/j.jad.2005.07.010</pub-id><pub-id pub-id-type="pmid">16256204</pub-id></mixed-citation>
      </ref>
      <ref id="B29">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moeller</surname><given-names>S.</given-names></name><name><surname>Yacoub</surname><given-names>E.</given-names></name><name><surname>Olman</surname><given-names>C. A.</given-names></name><name><surname>Auerbach</surname><given-names>E.</given-names></name><name><surname>Strupp</surname><given-names>J.</given-names></name><name><surname>Harel</surname><given-names>N.</given-names></name><etal/></person-group> (<year>2010</year>). <article-title>Multiband multislice GE-EPI at 7 tesla, with 16-fold acceleration using partial parallel imaging with application to high spatial and temporal whole-brain fMRI.</article-title>
<source><italic>Magn. Reson. Med.</italic></source>
<volume>63</volume>
<fpage>1144</fpage>–<lpage>1153</lpage>. <pub-id pub-id-type="doi">10.1002/mrm.22361</pub-id><pub-id pub-id-type="pmid">20432285</pub-id></mixed-citation>
      </ref>
      <ref id="B30">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Nemiah</surname><given-names>J. C.</given-names></name><name><surname>Freyberger</surname><given-names>H.</given-names></name><name><surname>Sifneos</surname><given-names>P. E.</given-names></name></person-group> (<year>1976</year>). <article-title>“Alexithymia: a view of the psychosomatic process,” in</article-title>
<source><italic>Modern Trends in Psychosomatic Medicine</italic></source>
<volume>Vol. 3</volume>
<role>ed.</role>
<person-group person-group-type="editor"><name><surname>Hill</surname><given-names>O. W.</given-names></name></person-group> (<publisher-loc>London</publisher-loc>: <publisher-name>Butterworths</publisher-name>) <fpage>430</fpage>–<lpage>439</lpage>.</mixed-citation>
      </ref>
      <ref id="B31">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pflugshaupt</surname><given-names>T.</given-names></name><name><surname>Mosimann</surname><given-names>U. P.</given-names></name><name><surname>Schmitt</surname><given-names>W. J.</given-names></name><name><surname>Von Wartburg</surname><given-names>R.</given-names></name><name><surname>Wurtz</surname><given-names>P.</given-names></name><name><surname>Lüthi</surname><given-names>M.</given-names></name><etal/></person-group> (<year>2007</year>). <article-title>To look or not to look at threat?: Scanpath differences within a group of spider phobics.</article-title>
<source><italic>J. Anxiety Disord.</italic></source>
<volume>21</volume>
<fpage>353</fpage>–<lpage>366</lpage>. <pub-id pub-id-type="doi">10.1016/j.janxdis.2006.05.005</pub-id><pub-id pub-id-type="pmid">16814514</pub-id></mixed-citation>
      </ref>
      <ref id="B32">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Platek</surname><given-names>S. M.</given-names></name><name><surname>Loughead</surname><given-names>J. W.</given-names></name><name><surname>Gur</surname><given-names>R. C.</given-names></name><name><surname>Busch</surname><given-names>S.</given-names></name><name><surname>Ruparel</surname><given-names>K.</given-names></name><name><surname>Phend</surname><given-names>N.</given-names></name><etal/></person-group> (<year>2006</year>). <article-title>Neural substrates for functionally discriminating self-face from personally familiar faces.</article-title>
<source><italic>Hum. Brain Mapp.</italic></source>
<volume>27</volume>
<fpage>91</fpage>–<lpage>98</lpage>. <pub-id pub-id-type="doi">10.1002/hbm.20168</pub-id><pub-id pub-id-type="pmid">16035037</pub-id></mixed-citation>
      </ref>
      <ref id="B33">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pollatos</surname><given-names>O.</given-names></name><name><surname>Herbert</surname><given-names>B. M.</given-names></name><name><surname>Schandry</surname><given-names>R.</given-names></name><name><surname>Gramann</surname><given-names>K.</given-names></name></person-group> (<year>2008</year>). <article-title>Impaired central processing of emotional faces in anorexia nervosa.</article-title>
<source><italic>Psychosom. Med.</italic></source>
<volume>70</volume>
<fpage>701</fpage>–<lpage>708</lpage>. <pub-id pub-id-type="doi">10.1097/PSY.0b013e31817e41e6</pub-id><pub-id pub-id-type="pmid">18606730</pub-id></mixed-citation>
      </ref>
      <ref id="B34">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Reilly</surname><given-names>J. L.</given-names></name><name><surname>Lencer</surname><given-names>R.</given-names></name><name><surname>Bishop</surname><given-names>J. R.</given-names></name><name><surname>Keedy</surname><given-names>S.</given-names></name><name><surname>Sweeney</surname><given-names>J. A.</given-names></name></person-group> (<year>2008</year>). <article-title>Pharmacological treatment effects on eye movement control.</article-title>
<source><italic>Brain Cogn.</italic></source>
<volume>68</volume>
<fpage>415</fpage>–<lpage>435</lpage>.<pub-id pub-id-type="pmid">19028266</pub-id></mixed-citation>
      </ref>
      <ref id="B35">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Russell</surname><given-names>T. A.</given-names></name><name><surname>Green</surname><given-names>M. J.</given-names></name><name><surname>Simpson</surname><given-names>I.</given-names></name><name><surname>Coltheart</surname><given-names>M.</given-names></name></person-group> (<year>2008</year>). <article-title>Remediation of facial emotion perception in schizophrenia: concomitant changes in visual attention.</article-title>
<source><italic>Schizophr. Res.</italic></source>
<volume>103</volume>
<fpage>248</fpage>–<lpage>256</lpage>. <pub-id pub-id-type="doi">10.1016/j.schres.2008.04.033</pub-id><pub-id pub-id-type="pmid">18565733</pub-id></mixed-citation>
      </ref>
      <ref id="B36">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sachdev</surname><given-names>P.</given-names></name><name><surname>Mondraty</surname><given-names>N.</given-names></name><name><surname>Wen</surname><given-names>W.</given-names></name><name><surname>Gulliford</surname><given-names>K.</given-names></name></person-group> (<year>2008</year>). <article-title>Brains of anorexia nervosa patients process self-images differently from non-self-images: an fMRI study.</article-title>
<source><italic>Neuropsychologia</italic></source>
<volume>46</volume>
<fpage>2161</fpage>–<lpage>2168</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuropsychologia.2008.02.031</pub-id><pub-id pub-id-type="pmid">18406432</pub-id></mixed-citation>
      </ref>
      <ref id="B37">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sheehan</surname><given-names>D. V.</given-names></name><name><surname>Lecrubier</surname><given-names>Y.</given-names></name><name><surname>Sheehan</surname><given-names>K. H.</given-names></name><name><surname>Amorim</surname><given-names>P.</given-names></name><name><surname>Janavs</surname><given-names>J.</given-names></name><name><surname>Weiller</surname><given-names>E.</given-names></name><etal/></person-group> (<year>1998</year>). <article-title>The Mini-International Neuropsychiatric Interview (MINI): the development and validation of a structured diagnostic psychiatric interview for DSM-IV and ICD-10.</article-title>
<source><italic>J. Clin. Psychiatry</italic></source>
<volume>59</volume>
<fpage>22</fpage>–<lpage>33</lpage>.<pub-id pub-id-type="pmid">9881538</pub-id></mixed-citation>
      </ref>
      <ref id="B38">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Striegel-Moore</surname><given-names>R. H.</given-names></name><name><surname>Silberstein</surname><given-names>L. R.</given-names></name><name><surname>Rodin</surname><given-names>J.</given-names></name></person-group> (<year>1993</year>). <article-title>The social self in bulimia nervosa: public self-consciousness, social anxiety, and perceived fraudulence.</article-title>
<source><italic>J. Abnorm. Psychol.</italic></source>
<volume>102</volume>
<issue>297</issue>
<pub-id pub-id-type="doi">10.1037/0021-843X.102.2.297</pub-id></mixed-citation>
      </ref>
      <ref id="B39">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sugiura</surname><given-names>M.</given-names></name><name><surname>Sassa</surname><given-names>Y.</given-names></name><name><surname>Jeong</surname><given-names>H.</given-names></name><name><surname>Horie</surname><given-names>K.</given-names></name><name><surname>Sato</surname><given-names>S.</given-names></name><name><surname>Kawashima</surname><given-names>R.</given-names></name></person-group> (<year>2008</year>). <article-title>Face-specific and domain-general characteristics of cortical responses during self-recognition.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>42</volume>
<fpage>414</fpage>–<lpage>422</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2008.03.054</pub-id><pub-id pub-id-type="pmid">18501639</pub-id></mixed-citation>
      </ref>
      <ref id="B40">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thiel</surname><given-names>A.</given-names></name><name><surname>Broocks</surname><given-names>A.</given-names></name><name><surname>Ohlmeier</surname><given-names>M.</given-names></name><name><surname>Jacoby</surname><given-names>G. E.</given-names></name></person-group> (<year>1995</year>). <article-title>Obsessive-compulsive disorder among patients with anorexia nervosa and bulimia nervosa.</article-title>
<source><italic>Am. J. Psychiatry</italic></source>
<volume>152</volume>
<fpage>72</fpage>–<lpage>75</lpage>.<pub-id pub-id-type="pmid">7802124</pub-id></mixed-citation>
      </ref>
      <ref id="B41">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tovée</surname><given-names>M. J.</given-names></name><name><surname>Emery</surname><given-names>J. L.</given-names></name><name><surname>Cohen–Tovée</surname><given-names>E. M.</given-names></name></person-group> (<year>2000</year>). <article-title>The estimation of body mass index and physical attractiveness is dependent on the observer’s own body mass index.</article-title>
<source><italic>Proc. R. Soc. Lond. B Biol. Sci.</italic></source>
<volume>267</volume>
<fpage>1987</fpage>–<lpage>1997</lpage>. <pub-id pub-id-type="doi">10.1098/rspb.2000.1240</pub-id></mixed-citation>
      </ref>
      <ref id="B42">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Troop</surname><given-names>N. A.</given-names></name><name><surname>Schmidt</surname><given-names>U. H.</given-names></name><name><surname>Treasure</surname><given-names>J. L.</given-names></name></person-group> (<year>2006</year>). <article-title>Feelings and fantasy in eating disorders: a factor analysis of the Toronto Alexithymia Scale.</article-title>
<source><italic>Int. J. Eat. Disord.</italic></source>
<volume>18</volume>
<fpage>151</fpage>–<lpage>157</lpage>. <pub-id pub-id-type="doi">10.1002/1098-108X(199509)18:2&lt;151::AID-EAT2260180207&gt;3.0.CO;2-E</pub-id><pub-id pub-id-type="pmid">7581417</pub-id></mixed-citation>
      </ref>
      <ref id="B43">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Uddin</surname><given-names>L. Q.</given-names></name><name><surname>Kaplan</surname><given-names>J. T.</given-names></name><name><surname>Molnar-Szakacs</surname><given-names>I.</given-names></name><name><surname>Zaidel</surname><given-names>E.</given-names></name><name><surname>Iacoboni</surname><given-names>M.</given-names></name></person-group> (<year>2005</year>). <article-title>Self-face recognition activates a frontoparietal mirror network in the right hemisphere: an event-related fMRI study.</article-title>
<source><italic>Neuroimage</italic></source>
<volume>25</volume>
<fpage>926</fpage>–<lpage>935</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.12.018</pub-id><pub-id pub-id-type="pmid">15808992</pub-id></mixed-citation>
      </ref>
      <ref id="B44">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vocks</surname><given-names>S.</given-names></name><name><surname>Busch</surname><given-names>M.</given-names></name><name><surname>Grönemeyer</surname><given-names>D.</given-names></name><name><surname>Schulte</surname><given-names>D.</given-names></name><name><surname>Herpertz</surname><given-names>S.</given-names></name><name><surname>Suchan</surname><given-names>B.</given-names></name></person-group> (<year>2010</year>). <article-title>Neural correlates of viewing photographs of one’s own body and another woman’s body in anorexia and bulimia nervosa: an fMRI study.</article-title>
<source><italic>J. Psychiatry Neurosci.</italic></source>
<volume>35</volume>
<fpage>163</fpage>–<lpage>176</lpage>. <pub-id pub-id-type="doi">10.1503/jpn.090048</pub-id><pub-id pub-id-type="pmid">20420767</pub-id></mixed-citation>
      </ref>
      <ref id="B45">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Walker-Smith</surname><given-names>G. J.</given-names></name><name><surname>Gale</surname><given-names>A. G.</given-names></name><name><surname>Findlay</surname><given-names>J. M.</given-names></name></person-group> (<year>1977</year>). <article-title>Eye movement strategies involved in face perception.</article-title>
<source><italic>Perception</italic></source>
<volume>6</volume>
<fpage>313</fpage>–<lpage>326</lpage>. <pub-id pub-id-type="doi">10.1068/p060313</pub-id><pub-id pub-id-type="pmid">866088</pub-id></mixed-citation>
      </ref>
      <ref id="B46">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>K. K.</given-names></name><name><surname>Werling</surname><given-names>D. M.</given-names></name><name><surname>Zucker</surname><given-names>N. L.</given-names></name><name><surname>Platt</surname><given-names>M. L.</given-names></name></person-group> (<year>2010</year>). <article-title>Altered social reward and attention in anorexia nervosa.</article-title>
<source><italic>Front. Psychol.</italic></source>
<volume>1</volume>:<issue>36</issue>
<pub-id pub-id-type="doi">10.3389/fpsyg.2010.00036</pub-id></mixed-citation>
      </ref>
      <ref id="B47">
        <mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wechsler</surname><given-names>D.</given-names></name></person-group> (<year>2001</year>). <source><italic>Wechsler Test of Adult Reading: WTAR.</italic></source>
<publisher-loc>San Antonio, TX</publisher-loc>: <publisher-name>Psychological Corporation</publisher-name>.</mixed-citation>
      </ref>
      <ref id="B48">
        <mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Williams</surname><given-names>L. M.</given-names></name><name><surname>Loughland</surname><given-names>C. M.</given-names></name><name><surname>Gordon</surname><given-names>E.</given-names></name><name><surname>Davidson</surname><given-names>D.</given-names></name></person-group> (<year>1999</year>). <article-title>Visual scanpaths in schizophrenia: is there a deficit in face recognition?</article-title>
<source><italic>Schizophr. Res.</italic></source>
<volume>40</volume>
<fpage>189</fpage>–<lpage>199</lpage>. <pub-id pub-id-type="doi">10.1016/S0920-9964(99)00056-0</pub-id><pub-id pub-id-type="pmid">10638857</pub-id></mixed-citation>
      </ref>
    </ref-list>
  </back>
</article>
